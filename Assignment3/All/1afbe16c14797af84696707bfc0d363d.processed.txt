   [1]Cornell University
   [2]Cornell University [3]Library
   [4]We gratefully acknowledge support from
   the Simons Foundation
   and member institutions

[5]arXiv.org > [6]cs > arXiv:1304.7045

   Search or Article-id
   ([7]Help | [8]Advanced search)
   ________________________   [All papers] Go!

   Full-text links:

Download:

     * [9]PDF
     * [10]Other formats

Current browse context:

   cs.LG
   [11]< prev | [12]next >
   [13]new | [14]recent | [15]1304

Change to browse by:

   [16]cs
   [17]cs.AI
   [18]stat
   [19]stat.ML

References & Citations

     * [20]NASA ADS

[21]DBLP - CS Bibliography

   [22]listing | [23]bibtex
   [24]Roi Livni
   [25]Shai Shalev-Shwartz
   [26]Ohad Shamir

Bookmark

   ([27]what is this?)
   [28]CiteULike logo [29]BibSonomy logo [30]Mendeley logo [31]Facebook
   logo [32]LinkedIn logo [33]del.icio.us logo [34]Digg logo [35]Reddit
   logo [36]ScienceWISE logo

Computer Science > Learning

Title: A Provably Efficient Algorithm for Training Deep Networks

   Authors: [37]Roi Livni, [38]Shai Shalev-Shwartz, [39]Ohad Shamir
   (Submitted on 26 Apr 2013)

     Abstract: We consider deep neural networks (formally equivalent to
     sum-product networks \cite{PoDo11}), in which the output of each
     node is a quadratic function of its inputs. Similar to other deep
     architectures, these networks can compactly represent any function
     on a finite training set. The main goal of this paper is the
     derivation of a provably efficient, layer-by-layer, algorithm for
     training such networks, which we denote as the \emph{Basis Learner}.
     Unlike most, if not all, previous algorithms for training deep
     neural networks, our algorithm comes with formal polynomial time
     convergence guarantees. Moreover, the algorithm is a universal
     learner in the sense that the training error is guaranteed to
     decrease at every iteration, and can eventually reach zero under
     mild conditions. We present practical implementations of this
     algorithm, as well as preliminary but quite promising experimental
     results. We also compare our deep architecture to other shallow
     architectures for learning polynomials, in particular kernel
     learning.

   Subjects: Learning (cs.LG); Artificial Intelligence (cs.AI); Machine
   Learning (stat.ML)
   Cite as: [40]arXiv:1304.7045 [cs.LG]
     (or [41]arXiv:1304.7045v1 [cs.LG] for this version)

Submission history

   From: Ohad Shamir [[42]view email]
   [v1] Fri, 26 Apr 2013 00:35:37 GMT (235kb,D)
   [43]Which authors of this paper are endorsers?

   Link back to: [44]arXiv, [45]form interface, [46]contact.

References

   1. http://www.cornell.edu/
   2. http://www.cornell.edu/
   3. http://www.library.cornell.edu/
   4. https://confluence.cornell.edu/x/9YhjCg
   5. http://arxiv.org/
   6. http://arxiv.org/list/cs/recent
   7. http://arxiv.org/help
   8. http://arxiv.org/find
   9. http://arxiv.org/pdf/1304.7045v1
  10. http://arxiv.org/format/1304.7045v1
  11. http://arxiv.org/prevnext?site=arxiv.org&id=1304.7045&context=cs.LG&function=prev
  12. http://arxiv.org/prevnext?site=arxiv.org&id=1304.7045&context=cs.LG&function=next
  13. http://arxiv.org/list/cs.LG/new
  14. http://arxiv.org/list/cs.LG/recent
  15. http://arxiv.org/list/cs.LG/1304
  16. http://arxiv.org/abs/1304.7045?context=cs
  17. http://arxiv.org/abs/1304.7045?context=cs.AI
  18. http://arxiv.org/abs/1304.7045?context=stat
  19. http://arxiv.org/abs/1304.7045?context=stat.ML
  20. http://adsabs.harvard.edu/cgi-bin/bib_query?arXiv:1304.7045
  21. http://www.informatik.uni-trier.de/~ley/db/
  22. http://www.informatik.uni-trier.de/~ley/db/journals/corr/corr1304.html#abs-1304-7045
  23. http://dblp.uni-trier.de/rec/bibtex/journals/corr/abs-1304-7045
  24. http://dblp.uni-trier.de/search/author?author=Roi%20Livni
  25. http://dblp.uni-trier.de/search/author?author=Shai%20Shalev-Shwartz
  26. http://dblp.uni-trier.de/search/author?author=Ohad%20Shamir
  27. http://arxiv.org/help/social_bookmarking
  28. http://arxiv.org/ct?url=http%3A%2F%2Fwww.citeulike.org%2Fposturl%3Furl%3Dhttp%3A%2F%2Farxiv.org%2Fabs%2F1304.7045%26title%3DA%2520Provably%2520Efficient%2520Algorithm%2520for%2520Training%2520Deep%2520Networks%26authors%3D&v=1347fcc8
  29. http://arxiv.org/ct?url=http%3A%2F%2Fwww.bibsonomy.org%2FBibtexHandler%3FrequTask%3Dupload%26url%3Dhttp%3A%2F%2Farxiv.org%2Fabs%2F1304.7045%26description%3DA%2520Provably%2520Efficient%2520Algorithm%2520for%2520Training%2520Deep%2520Networks&v=9d799633
  30. http://arxiv.org/ct?url=http%3A%2F%2Fwww.mendeley.com%2Fimport%2F%3Furl%3Dhttp%3A%2F%2Farxiv.org%2Fabs%2F1304.7045&v=457ebcb0
  31. http://arxiv.org/ct?url=http%3A%2F%2Fexport.arxiv.org%2Ffb%2Farxivpost%2F%3Furl%3Dhttp%3A%2F%2Farxiv.org%2Fabs%2F1304.7045&v=1bd32759
  32. http://arxiv.org/ct?url=http%3A%2F%2Fexport.arxiv.org%2Ffb%2Flinkedin_post%3Furl%3Dhttp%3A%2F%2Farxiv.org%2Fabs%2F1304.7045&v=37c68b77
  33. http://arxiv.org/ct?url=http%3A%2F%2Fdel.icio.us%2Fpost%3Furl%3Dhttp%3A%2F%2Farxiv.org%2Fabs%2F1304.7045%26description%3DA%2520Provably%2520Efficient%2520Algorithm%2520for%2520Training%2520Deep%2520Networks&v=56050a2b
  34. http://arxiv.org/ct?url=http%3A%2F%2Fdigg.com%2Fsubmit%3Furl%3Dhttp%3A%2F%2Farxiv.org%2Fabs%2F1304.7045%26title%3DA%2520Provably%2520Efficient%2520Algorithm%2520for%2520Training%2520Deep%2520Networks&v=47d5cf3c
  35. http://arxiv.org/ct?url=http%3A%2F%2Freddit.com%2Fsubmit%3Furl%3Dhttp%3A%2F%2Farxiv.org%2Fabs%2F1304.7045%26title%3DA%2520Provably%2520Efficient%2520Algorithm%2520for%2520Training%2520Deep%2520Networks&v=ab005f57
  36. http://arxiv.org/ct?url=http%3A%2F%2Fsciencewise.info%2Fbookmarks%2Fadd%3Furl%3Dhttp%3A%2F%2Farxiv.org%2Fabs%2F1304.7045&v=be6653c7
  37. http://arxiv.org/find/cs/1/au:+Livni_R/0/1/0/all/0/1
  38. http://arxiv.org/find/cs/1/au:+Shalev_Shwartz_S/0/1/0/all/0/1
  39. http://arxiv.org/find/cs/1/au:+Shamir_O/0/1/0/all/0/1
  40. http://arxiv.org/abs/1304.7045
  41. http://arxiv.org/abs/1304.7045v1
  42. http://arxiv.org/auth/show-email/e18075d8/1304.7045
  43. http://arxiv.org/auth/show-endorsers/1304.7045
  44. http://arxiv.org/
  45. http://arxiv.org/form
  46. http://arxiv.org/help/contact
